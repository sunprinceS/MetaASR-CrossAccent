asr_model:
  optimizer_opt: 
    k: 1.0
    warmup_steps: 25000


  idim: 83
  nheads: 4
  d_model: 256
  d_inner: 2048
  dropout: 0.1
  tgt_share_weight: 1

  encoder:
    nlayers: 4

  decoder:
    nlayers: 2

  pos_dropout: 0.1

solver:
  # Data options
  setting: 'mono-transformer-torch-trick-4e2d-weight-tying' # seems no need to add baseline or something
  data_root: 'data'
  total_epochs: 100
  #total_epochs: 2
  spm_mapping: 'data/valid_train_en_unigram150_units.txt'
  spm_model: 'data/valid_train_en_unigram150.model'
  label_smoothing: 0.2

  # Validation options
  #eval_ival: 20
  eval_ival: 10000
  log_ival: 20

  batch_size: 32 
  dev_batch_size: 32
  min_ilen: 10
  max_ilen: 1500
  dev_max_ilen: 3000
  half_batch_ilen: 512

  beam_decode:
    min_step_ratio: 0.0
    max_step_ratio: 1.0
    beam_size: 20
    att_w: 0.5
    ctc_w: 0.5
    lm_w: 0
